Ej1: Explique la programaciÃ³n estructurada:

La programaciÃ³n estructurada es una metodologÃ­a a seguir que lo que trata de lograr es que no haya diferencias estructurales entre un programa estÃ¡tico y uno dinÃ¡mico. Es decir, un programa estÃ¡tico se ejecuta "por una linea a la vez y en orden de texto", el objetivo es que un programa dinÃ¡mico se comporte lo mÃ¡s similar a eso.

Respuesta de GPT: La programaciÃ³n estructurada es una disciplina que construye programas solo con secuencia, selecciÃ³n e iteraciÃ³n (bloques con una entrada/una salida), sin goto, de modo que la estructura del cÃ³digo refleje el flujo de ejecuciÃ³n. Esto mejora legibilidad, verificaciÃ³n y testeo.

Ej2: Describa el proceso de codificaciÃ³n: Desarrollo dirigido por test.

El TDD (Test Driven Development) es un proceso de codificaciÃ³n que hace invierte la en cierto modo la estructura del proceso incremental clÃ¡sico. En primer lugar se necesita tener las especificaciones del trabajo, una vez las tengamos creamos test que prueben esas especificaciones. Luego de tener los test, escribimos cÃ³digo para que puedan pasar esos test, posteriormente se corren los scripts de tests. Si hubo errores volvemos a modificar el cÃ³digo, si no los hubo nos preguntamos si hace falta refactorizarlo. Si hace falta que lo refactoricemos entonces volvemos a la secciÃ³n de escribir cÃ³digo, si no hace falta nos preguntamos si cumple con las especificaciones. Si cumple entonces terminamos, si no cumple volvemos a escribir tests.

Respuesta de GPT: En TDD se avanza en ciclos Redâ€“Greenâ€“Refactor: (1) escribir un test que falle para el prÃ³ximo comportamiento, (2) escribir el mÃ­nimo cÃ³digo para pasarlo, y (3) refactorizar sin romper la suite. Se repite test por test hasta completar la historia. Los tests guÃ­an el diseÃ±o y funcionan como orÃ¡culo de regresiÃ³n.

Cuadro de TDD a modo de cÃ³digo:

void TDD(){
    Specification of the module;
    Write/add test for some functionality;
    Add code to pass test;
    Run test;
    if (errors){
        Fix;
        goto RunTest;
    }
    if (Code requires improvements){
        Improve code;
        goto Run test;
    }
    if (!All specs are coevered){
        goto Write/add test for some functionality;
    }
    Exit
}

Ej3: Describa exhaustivamente el modelo COCOMO.

COCOMO (Constructive Cost Model) es una estimaciÃ³n del costo de producciÃ³n de sw, normalmente calculado en persona/mes. Inicialmente se debe estimar el tamaÃ±o del proyecto, usualmente en KLOC, luego se establece si es un proyecto orgÃ¡nico, semirÃ­gido o rÃ­gido. OrgÃ¡nico es un proyecto pequeÃ±o que no requiere gran organizaciÃ³n, rÃ­gido son proyectos grandes que requieren mucha preparaciÃ³n y anÃ¡lisis, y semirÃ­gido es un termino medio entre los dos. La estimaciÃ³n se calcula con la formula a * tamaÃ±o^b con a y b constantes establecidas por el tipo de proyecto. Luego el resultado se corrige por un factor de correcciÃ³n que es productoria de 1 a 15 de fk. Donde fk son distintos factores como RELY (confianza en el proyecto) o TIME (capacidad del CPU).

Respuesta de GPT:

# COCOMO (Constructive Cost Model) â€” versiÃ³n â€œexamenâ€

## Idea central (frasecita)

Modelo empÃ­rico que **estima esfuerzo** de desarrollo en **persona-mes (PM)** a partir del **tamaÃ±o** (KLOC) y **ajustes por factores de costo**; de ahÃ­ se deriva **calendario** y **plan por fases**.

## Supuestos y pasos

1. **Insumo inicial: tamaÃ±o** del software (**KLOC**) â†’ puede obtenerse por histÃ³ricos o convertir desde **Function Points**.

2. **Modo del proyecto:**

   * **OrgÃ¡nico**: pequeÃ±o/estable, equipo con experiencia y requisitos conocidos.
   * **Semi-rÃ­gido**: mediano, mezcla de experiencia y restricciones.
   * **RÃ­gido**: grande/estricto, alta criticidad y fuertes restricciones HW/SW/estÃ¡ndares.

3. **Estimador inicial (A):** esfuerzo base
   [
   E_0 ;=; a\cdot(\text{KLOC})^{,b}
   ]
   con ((a,b)) segÃºn el modo (valores tÃ­picos usados en la cÃ¡tedra):

   * **OrgÃ¡nico:** (a=3.2,; b=1.05)
   * **Semi-rÃ­gido:** (a=3.0,; b=1.12)
   * **RÃ­gido:** (a=2.8,; b=1.20)

4. **Factores de costo (B):** **15 multiplicadores** (f_k) (software, hardware, personal, proyecto). El **esfuerzo ajustado** es:
   [
   E ;=; E_0 \cdot \prod_{k=1}^{15} f_k
   ]
   **Ejemplos (y quÃ© significan):**

   * **RELY** (*required reliability*): confiabilidad requerida del producto (â†‘ confiabilidad â‡’ â†‘ esfuerzo).
   * **DATA**: tamaÃ±o de BD interna.
   * **CPLX**: complejidad del producto.
   * **TIME**: restricciÃ³n de **tiempo de CPU**/performance (plazos de respuesta/throughput estrictos â‡’ â†‘ esfuerzo).
   * **STOR**: restricciÃ³n de memoria.
   * **VIRT/TURN**: entorno de ejecuciÃ³n y turnaround.
   * **ACAP/PCAP/AEXP/VEXP/LEXP**: capacidades/experiencia del equipo.
   * **MODP/TOOL**: modernidad del proceso/herramientas.
   * **SCED**: compresiÃ³n de cronograma.

5. **Calendario (C):** duraciÃ³n en meses (M). FÃ³rmulas de uso comÃºn:

   * **COCOMO (calendario):** ( M = 2.5 \cdot E^{0.38} )
   * (A veces tambiÃ©n se muestra **IBM**: ( M = 4.1\cdot E^{0.36} ))
     **TamaÃ±o de equipo** aproximado: ( N \approx \dfrac{E}{M} ).

6. **DistribuciÃ³n por fases (D):** repartir (E) en **diseÃ±o de producto / diseÃ±o detallado / codificaciÃ³n+TU / integraciÃ³n+test** con **porcentajes** que dependen del modo/tamaÃ±o (la tabla de la cÃ¡tedra). Esto da **plan y cronograma** detallados.

---

## QuÃ© corregir de tu texto

* **Definiciones de factores**:

  * **RELY** = **confiabilidad requerida** del **producto** (no â€œconfianza en el proyectoâ€).
  * **TIME** = **restricciÃ³n de tiempo de CPU / performance**, no â€œcapacidad del CPUâ€.


Ej4: Â¿QuÃ© es y para quÃ© sirve el orÃ¡culo de test? Â¿QuÃ© son y para quÃ© sirven los criterios de selecciÃ³n de tests? Â¿CuÃ¡l es la diferencia entre testing de caja blanca y el testing de caja negra?

El orÃ¡culo de test es una entidad que sabe cuÃ¡l es el resultado esperado para una entrada dada. Sirve para poder comparar los programas que estÃ¡n siendo testeados y determinar si los test dieron algÃºn fallo.
Los criterios de selecciÃ³n de test son una serie de pasos que nos permiten establecer una cantidad determinada de tests, para que haya una covertura significativa.
El testing de caja blanca testea todas las ramas del cÃ³digo, mientras que el testing de caja negra es totalmente funcional y no le interesa el cÃ³digo interno, sÃ³lo evalÃºa la entrada y la salida de una funciÃ³n.

Respuesta de GPT:

OrÃ¡culo: mecanismo que define el resultado esperado y decide pass/fail (especificaciÃ³n, golden master, propiedades, aserciones). Sirve para verificar automÃ¡tica y objetivamente cada test.

Criterios de selecciÃ³n: reglas para elegir una baterÃ­a finita de tests eficaz y manejable (equivalencias, lÃ­mites, pairwise; cobertura de sentencias/ramas/def-use). Sirven para maximizar detecciÃ³n de defectos con esfuerzo acotado.

Caja negra vs blanca: negra = desde requisitos (entradas/salidas, sin mirar cÃ³digo); blanca = desde la estructura interna (control/datos, metas de cobertura). Se complementan.

Ej5: Describa el proceso de inspecciÃ³n.

El proceso de inspecciÃ³n es tiene como objetivo detectar los defectos en los productos de trabajo mas no necesariamente corregirlos. Se siguen una serie de pasos, primero determinamos el poducto que vamos a revisar y se asignan los roles (moderador, autor, revisor,lector, escriba). Todos los participantes hacen previamente una revisiÃ³n induvidual y luego preparan una reunion grupal. Se revisa el producto y se anotan todos los desperfectos. El autor luego es el encargado de arreglarlos y el moderador decide si aprobarlo o mandarlo a revisiÃ³n nuevamente.


Respuesta de GPT:
InspecciÃ³n: proceso estructurado de revisiÃ³n por pares para detectar (no solucionar) defectos en artefactos (SRS, diseÃ±o, cÃ³digo, casos de test).
Roles: moderador (conduce), autor (aclara), revisores (detectan), lector (guÃ­a la lectura), escriba (registra).
Fases (ETVX):
Entry: paquete listo (artefacto, especificaciÃ³n, checklist, estÃ¡ndar) y equipo asignado.
Task: (1) preparaciÃ³n individual con checklist; (2) reuniÃ³n guiada por el lector: se registran defectos sin debatir soluciones; (3) reporte con lista y mÃ©tricas.
Verification: moderador verifica criterios de entrada (todos prepararon), control del tiempo y del foco (encontrar defectos).
Exit: se decide aceptar o reinspeccionar tras retrabajo del autor; el moderador cierra al comprobar correcciones.
MÃ©tricas: nÂº y severidad de defectos, tasa (defectos/hora), Ã¡reas problemÃ¡ticas â†’ mejora del proceso.

Ej6: Â¿QuÃ© es ETVX?


**ETVX** es un esquema para **definir y controlar procesos** de ingenierÃ­a de software. Ordena cada proceso en cuatro partes, haciendo explÃ­citos **quÃ© necesito para empezar, quÃ© hago, cÃ³mo verifico lo hecho y cuÃ¡ndo puedo darlo por terminado**:

* **E â€” Entry (Entradas):** **precondiciones** e **insumos** requeridos (artefactos, roles asignados, herramientas, baseline).
* **T â€” Task (Tareas):** **pasos concretos** del proceso y **productos intermedios** que se generan.
* **V â€” Verification (VerificaciÃ³n):** **controles y criterios** para comprobar calidad/cumplimiento (revisiones, mÃ©tricas, checklists).
* **X â€” eXit (Salida):** **entregables** y **criterios de salida** que habilitan pasar a la fase siguiente (go/no-go).

**Para quÃ© sirve:** elimina ambigÃ¼edades, **estandariza** la ejecuciÃ³n, facilita **auditorÃ­a y mediciÃ³n**, mejora la **trazabilidad entre fases** y soporta la **mejora continua** del proceso.

**Mini-ejemplo (diseÃ±o de tests):**
E: SRS aprobada y criterios de aceptaciÃ³n.
T: clases de equivalencia, valores lÃ­mite, especificar orÃ¡culos.
V: revisiÃ³n por pares y cobertura mÃ­nima acordada.
X: casos de prueba versionados y datos listos para ejecuciÃ³n.

Ej7:
Â¿QuÃ© es y para quÃ© sirve la refactorizaciÃ³n de cÃ³digo? Explique completamente los tipos mÃ¡s comunes y mencione al menos un ejemplo para cada uno de ellos.

RefactorizaciÃ³n es la tÃ©cnica de modificar internamente el cÃ³digo sin cambiar su comportamiento observable, para mejorar el diseÃ±o: legibilidad, cohesiÃ³n, bajo acoplamiento, menor complejidad, y mayor facilidad de prueba y cambio.
Sirve para: reducir deuda tÃ©cnica, bajar la complejidad ciclomatica, eliminar duplicaciÃ³n, hacer el cÃ³digo mÃ¡s mantenible y testable.
CÃ³mo se hace bien: en pasos pequeÃ±os, con tests en verde (idealmente TDD): aplico un refactor â†’ corro la suite â†’ todo sigue pasando.

- Extract Method (extraer mÃ©todo)
- Rename (renombrar sÃ­mbolo)
- Extract Variable / Introduce Explaining Variable (variable explicativa)
- Inline Method (inlinear mÃ©todo)
- Replace Temp with Query (reemplazar temporales por consultas)
- Introduce Parameter Object (objeto parÃ¡metro / data class)
- Replace Conditional with Polymorphism (condicional â†’ polimorfismo)
- Decompose Conditional (descomponer condicional)
- Consolidate Duplicate Conditional Fragments (consolidar duplicados en condicionales)
- Move Method / Move Field (mover mÃ©todo/campo)
- Replace Magic Number with Symbolic Constant (constante simbÃ³lica)
- Encapsulate Field / Encapsulate Collection (encapsular campo/colecciÃ³n)
- Extract Class / Inline Class (extraer/inlinear clase)
- Pull Up / Push Down Method or Field (subir/bajar a super/subclase)
- Replace Loop with Pipeline (map/filter/reduce)
- Introduce Guard Clauses (clÃ¡usulas de guarda)

Ej8: Explique el testing de caja blanca de cobertura de ramificaciones. DÃ© un ejemplo en el que un error pueda ser encontrado por el criterio de cobertura de ramificaciones y no por el de cobertura de sentencia.

Â¡Respuesta de examen! ğŸ‘‡

# Cobertura de **ramificaciones** (caja blanca)

**QuÃ© es:** criterio estructural que exige ejecutar **cada resultado** de **cada decisiÃ³n** al menos una vez (todos los **verdaderos** y todos los **falsos** de cada `if`, cada rama de un `switch`, cada salida de un bucle, etc.).
**Para quÃ© sirve:** detectar errores que aparecen sÃ³lo en **alguna** rama (p. ej., condiciones mal formuladas, ramas sin inicializar, `else` faltante, short-circuit no previsto).
**RelaciÃ³n con sentencias:** la cobertura de **ramas** suele **subsumir** (superar) a la cobertura de **sentencias** en cÃ³digo estructurado: podÃ©s tener 100% de **sentencias** sin haber ejercitado **todas** las decisiones en ambos sentidos.

---

# Ejemplo donde **ramas** encuentra un error y **sentencias** no

CÃ³digo (C-like):

```c
int foo(int x) {
    int y;                 // (1)
    if (x >= 0)            // (2) decisiÃ³n
        y = x;             // (3)
    // BUG: falta else -> y queda sin inicializar si x < 0
    return y;              // (4)
}
```

* **Con cobertura de sentencias**: un Ãºnico caso `x = 5` ejecuta (1)â€“(4).
  Resultado: **100% sentencias** (todas las lÃ­neas ejecutadas al menos una vez) y **no** se detecta el bug.
* **Con cobertura de ramificaciones**: necesitÃ¡s dos casos, uno con `x >= 0` y otro con `x < 0`.
  Con `x = -1` se toma la **rama falsa** del `if` y `y` se retorna **sin inicializar** â†’ **falla** detectada.

> Moral: ejecutar â€œtodas las lÃ­neasâ€ no garantiza haber probado **ambos resultados** de cada decisiÃ³n; la rama no recorrida puede esconder el defecto.

---

## Mini-checklist para contestar

* DefinÃ­ â€œramasâ€: **cada resultado** de **cada decisiÃ³n**.
* DecÃ­ el **objetivo**: cubrir **True/False** (o todas las salidas) para revelar errores lÃ³gicos.
* ContrastÃ¡ con **sentencias**: puede pasar 100% sentencias y **no** cubrir una rama â†’ riesgo.
* Dalo con un **ejemplo** como el de variable no inicializada / `else` faltante (o un `switch` con `default` incorrecto).


Ej9: Describa exhaustivamente la AdministraciÃ³n de Riesgos.


# AdministraciÃ³n de Riesgos â€” quÃ© es y para quÃ© sirve

**QuÃ© es:** conjunto de actividades para **reducir la probabilidad** de fracaso del proyecto y **minimizar el impacto** si eventos inciertos ocurren. Un **riesgo** es â€œcondiciÃ³n/evento incierto que puede causar la falla del proyectoâ€. **Objetivo:** bajar el impacto en **costos, calidad y tiempos** cuando los riesgos se materializan. 

---

# Proceso (fases y artefactos)

## 1) Planeamiento de la gestiÃ³n de riesgos

DefinÃ­s **cÃ³mo** vas a gestionar: fuentes, responsables, criterios de probabilidad/impacto, formato del **registro de riesgos**, y ritmo de revisiÃ³n. (La cÃ¡tedra lo presenta dentro de â€œAdministraciÃ³n del riesgo: EvaluaciÃ³n + Controlâ€ y distingue actividades de **planeamiento** vs **ejecuciÃ³n/seguimiento**). 

## 2) IdentificaciÃ³n

Listar **posibles riesgos** mediante checklists, lecciones aprendidas, *brainstorming* (â€œÂ¿quÃ© pasarÃ­a siâ€¦?â€), etc. (se construye el **registro de riesgos** con descripciÃ³n, causas, disparadores). 

> **9 factores frecuentes** (ejemplos que la cÃ¡tedra remarca): **personal** no entrenado; **tiempos/costos irreales**; **componentes externas** incompatibles; **discrepancias** con requerimientos o **UI**; **arquitectura/desempeÃ±o** mal evaluados; **cambios continuos**; **software legado**; **tareas tercerizadas** demoradas. 

## 3) AnÃ¡lisis y priorizaciÃ³n

Para cada riesgo, estimar **probabilidad** y **impacto**, y calcular el **RE (Risk Exposure)** = probabilidad Ã— impacto (valor esperado de la pÃ©rdida). PriorizÃ¡s y enfocÃ¡s mitigaciÃ³n en los **RE mÃ¡s altos**. 

> **Matriz probabilidadâ€“impacto**: clasificar **Bajo/Medio/Alto** en ambos e **identificar AA y AM/MA** para concentrar esfuerzos (tÃ©cnica eficaz en proyectos chicos/medianos). 

## 4) Plan de respuesta (control de riesgos)

Estrategias:

* **Evitar**: cambiar el plan para eliminar el riesgo (p. ej., usar **hardware ya verificado** en lugar del nuevo). 
* **Mitigar**: **reducir probabilidad/impacto** con acciones planificadas (tienen **costo extra** y **cronograma**).  
* **Transferir/Aceptar**: si aplica (seguro, contrato; o aceptaciÃ³n con **planes de contingencia**).

**Ejemplos de mitigaciÃ³n (que pueden preguntarte):**

* *Demasiados cambios de requerimientos*: procedimiento formal de cambios, visibilizar impacto acumulado, negociar pagos por esfuerzo real. 
* *Desgaste del personal*: mÃºltiples recursos en Ã¡reas clave, *team building*, rotaciÃ³n de tareas, *backup*, documentaciÃ³n, seguir proceso de cambios. 
* *PlanificaciÃ³n irreal*: renegociar tiempos, paralelizar tareas, alistar recursos temprano, automatizar, renegociar camino crÃ­tico, pagos por esfuerzo real. 

> **Plan de mitigaciÃ³n**: lista de **pasos concretos**, costeados y **calendarizados**; **distintos** de las **acciones de contingencia** (que solo se ejecutan **si** el riesgo ocurre). **RevisiÃ³n periÃ³dica**. 

## 5) Seguimiento y control

Durante la ejecuciÃ³n: **monitorear** disparadores, actualizar el **registro**, verificar que se ejecutan las **mitigaciones**, y decidir **retrabajos**. (La cÃ¡tedra liga esto con el **seguimiento del proyecto**: medir tiempo, esfuerzo, defectos, tamaÃ±o, y tomar acciones correctivas).  

---

# QuÃ© te pueden pedir â€œde memoriaâ€

* **DefiniciÃ³n de riesgo** y **objetivo** de la gestiÃ³n. 
* **Fases**: identificaciÃ³n â†’ anÃ¡lisis/priorizaciÃ³n (RE) â†’ plan de respuesta (evitar/mitigar/transferir/aceptar) â†’ seguimiento. 
* **Matriz probâ€“impacto** y **RE** (fÃ³rmula).  
* **Ejemplos concretos** de mitigaciÃ³n (requisitos cambiantes, desgaste, tiempos irreales).   
* **Plan de mitigaciÃ³n** vs **contingencia** y **revisiones periÃ³dicas**. 

Con esto tenÃ©s una respuesta exhaustiva, alineada a las filminas de â€œPlaneamientoâ€. Â¿QuerÃ©s que te deje una **plantilla de registro de riesgos** (ID, causa, disparador, prob, impacto, RE, estrategia, dueÃ±o, fecha de revisiÃ³n)?

